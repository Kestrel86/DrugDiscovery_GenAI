{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "RNN model testing"
      ],
      "metadata": {
        "id": "rhf0zVh-psv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi -qqq\n",
        "!git clone https://github.com/molecularsets/moses.git\n"
      ],
      "metadata": {
        "id": "rTjrUH15NieO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f718c7b-c70d-4c0f-9e73-9bc2800c82cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'moses'...\n",
            "remote: Enumerating objects: 1957, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1957 (delta 0), reused 2 (delta 0), pack-reused 1953 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1957/1957), 164.05 MiB | 49.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1068/1068), done.\n",
            "Filtering content: 100% (68/68), 323.72 MiB | 153.18 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: open train.csv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('moses/data/train.csv')\n",
        "print(df.tail())\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "s5wTTBW2PqNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f032d0c0-87fd-45fb-816d-390704c5016d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           SMILES  SPLIT\n",
            "1584658                      N#Cc1c(Br)cnc(N)c1Br  train\n",
            "1584659        COC(=O)c1cc(CNC(=O)OC(C)(C)C)ccc1C  train\n",
            "1584660                    NC(=O)c1ccc2ccccc2c1Br  train\n",
            "1584661  CC(=O)Nc1cccc(-c2nc3cc(C)ccc3[nH]c2=O)c1  train\n",
            "1584662   CC(NC(=O)OC(C)(C)C)c1nc(CO)nn1Cc1ccccc1  train\n",
            "(1584663, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "JwVP3ljmt0wL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem, RDLogger\n",
        "RDLogger.DisableLog('rdApp.*')  # Suppress RDKit warnings\n",
        "\n",
        "# Function to add start and end tokens\n",
        "def process_smiles(smiles_list):\n",
        "    return [\"^\" + s + \"$\" for s in smiles_list]\n",
        "\n",
        "# Create character dictionaries including special tokens\n",
        "def create_vocab(smiles_list):\n",
        "    all_chars = sorted(list(set(''.join(smiles_list))))\n",
        "    char2idx = {ch: i + 1 for i, ch in enumerate(all_chars)}\n",
        "    char2idx['<PAD>'] = 0  # Padding token\n",
        "    idx2char = {i: ch for ch, i in char2idx.items()}\n",
        "    return char2idx, idx2char, len(char2idx)\n",
        "\n",
        "# Enhanced tokenization\n",
        "def tokenize(smiles, char2idx):\n",
        "    return [char2idx.get(c, 0) for c in smiles]  # Default to 0 if unknown\n",
        "\n",
        "def detokenize(tokens, idx2char):\n",
        "    return ''.join([idx2char.get(t, '') for t in tokens if t != 0])\n",
        "\n",
        "# Improved dataset class\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, smiles_list, char2idx, seq_len=120):\n",
        "        self.smiles_list = smiles_list\n",
        "        self.char2idx = char2idx\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles_list[idx]\n",
        "        if len(smiles) > self.seq_len:\n",
        "            smiles = smiles[:self.seq_len]\n",
        "\n",
        "        tokens = tokenize(smiles, self.char2idx)\n",
        "        x = torch.tensor(tokens[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(tokens[1:], dtype=torch.long)\n",
        "\n",
        "        # Padding\n",
        "        pad_len = self.seq_len - 1 - len(x)\n",
        "        if pad_len > 0:\n",
        "            x = torch.cat([x, torch.zeros(pad_len, dtype=torch.long)])\n",
        "            y = torch.cat([y, torch.zeros(pad_len, dtype=torch.long)])\n",
        "\n",
        "        return x, y\n",
        "\n",
        "# Enhanced RNN model\n",
        "class RNNGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=512, num_layers=3, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        batch_size = x.size(0)\n",
        "        emb = self.dropout(self.embedding(x))\n",
        "\n",
        "        if hidden is None:\n",
        "            # Initialize hidden states\n",
        "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
        "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)\n",
        "            hidden = (h0, c0)\n",
        "\n",
        "        out, hidden = self.rnn(emb, hidden)\n",
        "        out = self.dropout(out)\n",
        "        logits = self.fc(out)\n",
        "        return logits, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return (h0, c0)\n",
        "\n",
        "# Sample a new molecule\n",
        "def generate_molecule(model, char2idx, idx2char, device, max_len=100, temperature=0.8):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Start with the start token\n",
        "        start_token = char2idx['^']\n",
        "        current = torch.tensor([[start_token]], dtype=torch.long).to(device)\n",
        "        hidden = None\n",
        "        result = [start_token]\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            output, hidden = model(current, hidden)\n",
        "            output = output[:, -1, :] / temperature\n",
        "            probs = torch.softmax(output, dim=-1)\n",
        "\n",
        "            # Sample from the probability distribution\n",
        "            next_token = torch.multinomial(probs, 1).item()\n",
        "            result.append(next_token)\n",
        "            current = torch.tensor([[next_token]], dtype=torch.long).to(device)\n",
        "\n",
        "            # Stop if end token is generated\n",
        "            if idx2char[next_token] == '$':\n",
        "                break\n",
        "\n",
        "        generated = detokenize(result, idx2char)\n",
        "        # Remove start/end tokens for validation\n",
        "        clean_smiles = generated.replace('^', '').replace('$', '')\n",
        "        return clean_smiles, is_valid_smiles(clean_smiles)\n",
        "\n",
        "# Validate SMILES with RDKit\n",
        "def is_valid_smiles(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return mol is not None\n",
        "\n",
        "# Training with teacher forcing and validation\n",
        "def train_model(model, dataloader, optimizer, criterion, device, epochs,\n",
        "                char2idx, idx2char, save_path='smiles_rnn_model.pth'):\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for x, y in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            logits, _ = model(x)\n",
        "            loss = criterion(logits.view(-1, len(char2idx)), y.view(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)  # Gradient clipping\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1} loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Generate and validate some molecules\n",
        "        if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
        "            valid_count = 0\n",
        "            n_samples = 10\n",
        "            print(\"\\nGenerating sample molecules:\")\n",
        "            for _ in range(n_samples):\n",
        "                mol, valid = generate_molecule(model, char2idx, idx2char, device)\n",
        "                validity = \"✓\" if valid else \"✗\"\n",
        "                print(f\"{mol} {validity}\")\n",
        "                if valid:\n",
        "                    valid_count += 1\n",
        "            print(f\"Validity: {valid_count}/{n_samples} ({valid_count/n_samples*100:.1f}%)\")\n",
        "\n",
        "        # Save best model\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"Model saved to {save_path}\")\n",
        "\n",
        "# Main training pipeline\n",
        "def run_training(dataframe, smiles_column='SMILES', batch_size=128, epochs=20):\n",
        "    # Get SMILES strings from DataFrame\n",
        "    smiles_list = dataframe[smiles_column].tolist()\n",
        "\n",
        "    # Process data\n",
        "    processed_smiles = process_smiles(smiles_list)\n",
        "    char2idx, idx2char, vocab_size = create_vocab(processed_smiles)\n",
        "\n",
        "    # Create dataset and data loader\n",
        "    dataset = SMILESDataset(processed_smiles, char2idx, seq_len=120)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Setup model\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = RNNGenerator(vocab_size).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    # Train\n",
        "    train_model(model, loader, optimizer, criterion, device, epochs=epochs,\n",
        "                char2idx=char2idx, idx2char=idx2char)\n",
        "\n",
        "    return model, char2idx, idx2char\n",
        "\n",
        "# Generate a batch of molecules\n",
        "def generate_molecules(model, char2idx, idx2char, device, n=25, temperature=0.8):\n",
        "    valid_mols = []\n",
        "    attempts = 0\n",
        "    max_attempts = n * 5  # Try up to 5x the requested number\n",
        "\n",
        "    while len(valid_mols) < n and attempts < max_attempts:\n",
        "        smiles, valid = generate_molecule(model, char2idx, idx2char, device, temperature=temperature)\n",
        "        attempts += 1\n",
        "        if valid:\n",
        "            # Check for duplicates\n",
        "            if smiles not in valid_mols:\n",
        "                valid_mols.append(smiles)\n",
        "\n",
        "    return valid_mols, len(valid_mols)/attempts if attempts > 0 else 0"
      ],
      "metadata": {
        "id": "1ydRfMAmLxU5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "\n",
        "def is_valid_molecule(smiles: str) -> dict:\n",
        "    try:\n",
        "        # 1. Try to parse SMILES without sanitization\n",
        "        mol = Chem.MolFromSmiles(smiles, sanitize=False)\n",
        "        if mol is None:\n",
        "            return {'valid': False, 'reason': 'SMILES parsing failed'}\n",
        "\n",
        "        # 2. Try manual sanitization (catches bad chemistry)\n",
        "        Chem.SanitizeMol(mol)\n",
        "\n",
        "        # 3. Check for multiple fragments (optional strictness)\n",
        "        if '.' in smiles:\n",
        "            return {'valid': False, 'reason': 'Multiple fragments detected'}\n",
        "\n",
        "        # 4. Check for atoms with crazy formal charges\n",
        "        for atom in mol.GetAtoms():\n",
        "            if abs(atom.GetFormalCharge()) > 5:\n",
        "                return {'valid': False, 'reason': f'Unusual charge on atom {atom.GetSymbol()}'}\n",
        "\n",
        "        # If all checks pass\n",
        "        return {'valid': True, 'reason': 'Molecule is valid'}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {'valid': False, 'reason': f'Exception during validation: {str(e)}'}\n"
      ],
      "metadata": {
        "id": "4PL8B4avokhO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    df = pd.read_csv('moses/data/train.csv')\n",
        "    print(\"Dataset information:\")\n",
        "    print(df.head())\n",
        "    print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "    # Check if 'SMILES' column exists, adjust if needed\n",
        "    smiles_column = 'SMILES'\n",
        "    if smiles_column not in df.columns:\n",
        "        # Try to find a column that might contain SMILES strings\n",
        "        for col in df.columns:\n",
        "            if any(c in '()[]=' for c in df[col].iloc[0]):\n",
        "                smiles_column = col\n",
        "                print(f\"Using column '{smiles_column}' for SMILES data\")\n",
        "                break\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"\\nTraining model on {df.shape[0]} SMILES strings...\")\n",
        "    model, char2idx, idx2char = run_training(df, smiles_column=smiles_column)\n",
        "\n",
        "    # Generate and evaluate new molecules\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"\\nGenerating new molecules...\")\n",
        "    molecules, validity_rate = generate_molecules(model, char2idx, idx2char, device, n=20)\n",
        "\n",
        "    print(f\"\\nGenerated {len(molecules)} valid molecules with {validity_rate*100:.1f}% validity rate\")\n",
        "    print(\"\\nSample valid molecules:\")\n",
        "    for i, mol in enumerate(molecules[:10], 1):\n",
        "        print(f\"{i}. {mol}\")\n",
        "\n",
        "    # Optional: Save to CSV\n",
        "    if molecules:\n",
        "        output_df = pd.DataFrame({'generated_smiles': molecules})\n",
        "        output_path = 'generated_molecules.csv'\n",
        "        output_df.to_csv(output_path, index=False)\n",
        "        print(f\"\\nSaved generated molecules to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "cTEoc-mgMH55",
        "outputId": "8bbf63cb-54c3-43b2-87f6-975e02fdb2ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset information:\n",
            "                                   SMILES  SPLIT\n",
            "0  CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1  train\n",
            "1    CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1  train\n",
            "2     Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO  train\n",
            "3        Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C  train\n",
            "4          CC1Oc2ccc(Cl)cc2N(CC(O)CO)C1=O  train\n",
            "Dataset shape: (1584663, 2)\n",
            "\n",
            "Training model on 1584663 SMILES strings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20:   2%|▏         | 252/12381 [00:05<04:41, 43.04it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5b78ec6140df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nTraining model on {df.shape[0]} SMILES strings...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar2idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx2char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmiles_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Generate and evaluate new molecules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ed9ef81583f2>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(dataframe, smiles_column, batch_size, epochs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     train_model(model, loader, optimizer, criterion, device, epochs=epochs,\n\u001b[0m\u001b[1;32m    193\u001b[0m                 char2idx=char2idx, idx2char=idx2char)\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-ed9ef81583f2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, optimizer, criterion, device, epochs, char2idx, idx2char, save_path)\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Evaluation\n",
        "\n",
        "molecules = [\n",
        "    \"CC(=O)Oc1ccccc1C(=O)O\",     # Aspirin\n",
        "    \"C1=CC=CN=C1\",               # Pyridine\n",
        "    \"C1=CC=CC=C1\",               # Benzene\n",
        "    \"C1CC1C1\",                   # Invalid (bad ring closure)\n",
        "    \"C(=O)(=O)O\",                # Bad carbon valence\n",
        "    \"CC(C)(C)(C)(C)\",            # Hypervalent carbon\n",
        "    \"C[N+](C)(C)(C)C\",           # Reasonable charged species\n",
        "]\n",
        "\n",
        "for smiles in molecules:\n",
        "    print(smiles, \"->\", is_valid_molecule(smiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsbapR2DonAI",
        "outputId": "a0c73d6d-a7f0-4bc5-ed73-fd42ceba751e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CC(=O)Oc1ccccc1C(=O)O -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "C1=CC=CN=C1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "C1=CC=CC=C1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "C1CC1C1 -> {'valid': False, 'reason': 'SMILES parsing failed'}\n",
            "C(=O)(=O)O -> {'valid': False, 'reason': 'Exception during validation: Explicit valence for atom # 0 C, 5, is greater than permitted'}\n",
            "CC(C)(C)(C)(C) -> {'valid': False, 'reason': 'Exception during validation: Explicit valence for atom # 1 C, 5, is greater than permitted'}\n",
            "C[N+](C)(C)(C)C -> {'valid': False, 'reason': 'Exception during validation: Explicit valence for atom # 1 N, 4, is greater than permitted'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_molecules = [\"Cc1noc(C)c1CCC(=O)N(C)Cc1ccsc1\",\n",
        "\"O=C(Nc1ccc(S(=O)(=O)C2CCCC2)cc1)C1CCCO1\",\n",
        "\"CCC(C)NC(=O)C1CCCN1C(=O)Nc1ccccc1OC\",\n",
        "\"Cc1ccc(NS(=O)(=O)c2c(C)noc2C)c(Cl)c1\",\n",
        "\"O=C(COc1ccccc1)Nc1ccc(N2CCOCC2)nc1\",\n",
        "\"CC(Oc1ccc(C(F)(F)F)cc1)C(=O)NCC1CCCO1\",\n",
        "\"Cc1ccc(CN(C)C(=O)C(C)N2CCN(c3cccs3)CC2)o1\",\n",
        "\"Cc1ccccc1CCNC(=O)CCn1cnc2ccccc2c1=O\",\n",
        "\"O=C(COc1ccccc1F)NCc1cc(-c2cccs2)on1\",\n",
        "\"Cc1cc(C(=O)N2CCC(O)C2)ccc1NC(=O)c1ccccc1O\"]\n",
        "\n",
        "for smiles in generated_molecules:\n",
        "    print(smiles, \"->\", is_valid_molecule(smiles))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbBDloUU0QG1",
        "outputId": "41b1ab67-ad1a-4a83-de44-6f812d91835a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cc1noc(C)c1CCC(=O)N(C)Cc1ccsc1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "O=C(Nc1ccc(S(=O)(=O)C2CCCC2)cc1)C1CCCO1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "CCC(C)NC(=O)C1CCCN1C(=O)Nc1ccccc1OC -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "Cc1ccc(NS(=O)(=O)c2c(C)noc2C)c(Cl)c1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "O=C(COc1ccccc1)Nc1ccc(N2CCOCC2)nc1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "CC(Oc1ccc(C(F)(F)F)cc1)C(=O)NCC1CCCO1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "Cc1ccc(CN(C)C(=O)C(C)N2CCN(c3cccs3)CC2)o1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "Cc1ccccc1CCNC(=O)CCn1cnc2ccccc2c1=O -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "O=C(COc1ccccc1F)NCc1cc(-c2cccs2)on1 -> {'valid': True, 'reason': 'Molecule is valid'}\n",
            "Cc1cc(C(=O)N2CCC(O)C2)ccc1NC(=O)c1ccccc1O -> {'valid': True, 'reason': 'Molecule is valid'}\n"
          ]
        }
      ]
    }
  ]
}