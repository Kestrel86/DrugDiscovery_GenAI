Seems that more epochs, the wider it gets in scope? From what I heard in class by student


Train VAE with Flow loss, use maximum likelihood function
Take out latent, 
Start from latent space, new on Z
Get one molecule output without VAE
That is the generated molecule
Test validity with RDK for molecule structure 

Performance is not the focus 

Meeting:

CharRNN, usually input a chcaracter and it should output another letter and repeat the process

But think of possibly adding blocks of molecules such as AGTA and put it into the process to output possibly another block

Higher probability instead of one letter but instead a block

Its just remembering the training data 

Not a kind of image data, so reconstructing

GLOW was more preferred 

Encoding technique

One-hot encoding (for strings, giving each word a code) or protein-2-Vect

21 unique values, providing them code? Having a length of 21 with there being 21 unique values

Strings cannot normally go into a model