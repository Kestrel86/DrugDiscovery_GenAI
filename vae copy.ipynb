{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e53c5634",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e53c5634",
        "outputId": "61bc9203-bde6-4269-978f-c60c57cb1128"
      },
      "outputs": [],
      "source": [
        "# !pip install rdkit-pypi\n",
        "# !git clone https://github.com/molecularsets/moses.git\n",
        "\n",
        "import matplotlib as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from rdkit import Chem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1c227beb",
      "metadata": {
        "id": "1c227beb"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def load_smiles_from_csv(path, split_type='train'):\n",
        "    '''\n",
        "    Loads SMILES strings from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the CSV file\n",
        "        split_type (str): Split type ('train' or 'test')\n",
        "\n",
        "    Returns:\n",
        "        list: List of SMILES strings\n",
        "    '''\n",
        "    smiles = []\n",
        "    with open(path, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            if row['SPLIT'].strip().lower() == split_type:\n",
        "                smiles.append(row['SMILES'].strip())\n",
        "    return smiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "QFYVVczcKLoV",
      "metadata": {
        "id": "QFYVVczcKLoV"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Functions are from the RNN model we have but not entirely sure where they would fit in the VAE\n",
        "Currently working on implementation, the process_smiles function may help in creating valid molecules\n",
        "'''\n",
        "\n",
        "# Function to add start and end tokens\n",
        "def process_smiles(smiles_list):\n",
        "    return [\"^\" + s + \"$\" for s in smiles_list]\n",
        "\n",
        "# Create character dictionaries including special tokens\n",
        "def create_vocab(smiles_list):\n",
        "    all_chars = sorted(list(set(''.join(smiles_list))))\n",
        "    char2idx = {ch: i + 1 for i, ch in enumerate(all_chars)}\n",
        "    char2idx[''] = 0  # Padding token\n",
        "    idx2char = {i: ch for ch, i in char2idx.items()}\n",
        "    return char2idx, idx2char, len(char2idx)\n",
        "\n",
        "# Enhanced tokenization\n",
        "def tokenize(smiles, char2idx):\n",
        "    return [char2idx.get(c, 0) for c in smiles]  # Default to 0 if unknown\n",
        "\n",
        "def detokenize(tokens, idx2char):\n",
        "    return ''.join([idx2char.get(t, '') for t in tokens if t != 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2bd0c0a6",
      "metadata": {
        "id": "2bd0c0a6"
      },
      "outputs": [],
      "source": [
        "def extract_unique_chars(smiles_list):\n",
        "    '''\n",
        "    Extracts unique characters from a list of SMILES strings.\n",
        "\n",
        "    Args:\n",
        "        smiles_list (list): List of SMILES strings\n",
        "\n",
        "    Returns:\n",
        "        list: List of unique characters\n",
        "    '''\n",
        "    unique_chars = set()\n",
        "    for smiles in smiles_list:\n",
        "        unique_chars.update(smiles.strip())\n",
        "    return sorted(unique_chars)\n",
        "\n",
        "def clean_smiles(smiles):\n",
        "  '''\n",
        "  Cleans a SMILES string by removing unwanted characters.\n",
        "\n",
        "  Args:\n",
        "      smiles (str): SMILES string\n",
        "\n",
        "  Returns:\n",
        "      str: Cleaned SMILES string\n",
        "  '''\n",
        "  # Remove unwanted metadata like \",train\" or \",SPLIT\"\n",
        "  return smiles.split(',')[0].strip()\n",
        "\n",
        "def decode_smiles(one_hot_tensor, idx_to_char):\n",
        "    '''\n",
        "    Decodes a one-hot encoded tensor back to SMILES.\n",
        "\n",
        "    Args:\n",
        "        one_hot_tensor (torch.Tensor): One-hot encoded tensor\n",
        "    '''\n",
        "    smiles = ''\n",
        "    one_hot_tensor = one_hot_tensor.view(-1, len(idx_to_char))  # unflatten\n",
        "    for row in one_hot_tensor:\n",
        "        idx = row.argmax().item()\n",
        "        smiles += idx_to_char[idx]\n",
        "    return smiles.strip()\n",
        "\n",
        "def verify_smiles(smiles):\n",
        "  '''\n",
        "  Verifies the validity of a SMILES string using RDKit.\n",
        "\n",
        "  Args:\n",
        "      smiles (str): SMILES string to verify\n",
        "\n",
        "  Returns:\n",
        "      bool: True if valid, False otherwise\n",
        "  '''\n",
        "  mol = Chem.MolFromSmiles(smiles)\n",
        "  return mol is not None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2dd695f2",
      "metadata": {
        "id": "2dd695f2"
      },
      "outputs": [],
      "source": [
        "# Generate a new molecule from VAE by sampling from the latent space\n",
        "def generate_smiles(model, latent_dim, idx_to_char, max_length, vocab_size, temperature=1.0):\n",
        "    '''\n",
        "    Generates a new SMILES string by sampling from the VAE's latent space.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): VAE model\n",
        "        latent_dim (int): Dimension of the latent space\n",
        "    '''\n",
        "    z = torch.randn(1, latent_dim).to(model.fc1.weight.device)  # Ensure z is on the same device as the model\n",
        "    with torch.no_grad():\n",
        "        generated = model.decode(z)\n",
        "\n",
        "    # Add postprocessing to convert to SMILES\n",
        "    probs = F.softmax(generated.view(max_length, vocab_size) / temperature, dim=-1)\n",
        "\n",
        "    # Sample the next character from the probability distribution\n",
        "    generated_tokens_indices = torch.multinomial(probs, 1).cpu().numpy().flatten()\n",
        "\n",
        "    # Iterate through indices to build the SMILES string\n",
        "    generated_smiles = \"\".join([idx_to_char.get(i, \"\") for i in generated_tokens_indices])\n",
        "    generated_smiles = generated_smiles.replace('^', '').replace('$', '')\n",
        "\n",
        "    # Verification using rdkit\n",
        "    is_valid = verify_smiles(generated_smiles)\n",
        "    if is_valid:\n",
        "      return generated_smiles\n",
        "    else:\n",
        "      return \"INVALID\"\n",
        "\n",
        "    # return generated_smiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "062ff3ba",
      "metadata": {
        "id": "062ff3ba"
      },
      "outputs": [],
      "source": [
        "# Dataset class for SMILES strings\n",
        "\n",
        "# Contemplate Protein To Vector Encoding\n",
        "class SMILESDataset(Dataset):\n",
        "    def __init__(self, smiles_list, max_length=150, char_to_idx=None):\n",
        "        '''\n",
        "        Initializes the SMILESDataset with a list of SMILES strings.\n",
        "\n",
        "        Args:\n",
        "            smiles_list (list): List of SMILES strings\n",
        "            max_length (int): Maximum length of the SMILES strings\n",
        "            char_to_idx (dict): Character-to-index mapping\n",
        "\n",
        "        The dataset will one-hot encode each character in a SMILES string to a fixed-size tensor of shape (max_length * vocab_size).\n",
        "        If a SMILES string is shorter than max_length, it will be padded with zeros. If longer, it will be truncated.\n",
        "        '''\n",
        "        self.smiles_list = smiles_list\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if char_to_idx is None:\n",
        "            raise ValueError(\"Please provide a fixed character-to-index mapping\")\n",
        "            # self.char_to_idx, self.idx_to_char = build_vocabulary(smiles_list)\n",
        "        else:\n",
        "            self.char_to_idx = char_to_idx\n",
        "            self.idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
        "\n",
        "        self.vocab_size = len(self.char_to_idx)\n",
        "\n",
        "        original_count = len(smiles_list)\n",
        "        filtered = []\n",
        "        invalid_count = 0\n",
        "\n",
        "        for s in smiles_list:\n",
        "            s = s.strip()\n",
        "            if all(c in self.char_to_idx for c in s):\n",
        "                filtered.append(s)\n",
        "            else:\n",
        "                invalid_count += 1\n",
        "        print(f\"Total: {original_count}, Valid: {len(filtered)}, Invalid: {invalid_count}\")\n",
        "        self.smiles_list = filtered\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        Returns:\n",
        "            int: Number of valid SMILES strings in the dataset\n",
        "        '''\n",
        "\n",
        "        return len(self.smiles_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        Fetches the encoded version of a SMILES string at a given index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the SMILES string to retrieve\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: One-hot encoded tensor of the SMILES string of shape (max_length * vocab_size)\n",
        "        '''\n",
        "\n",
        "        smiles = self.smiles_list[idx]\n",
        "\n",
        "        # One-hot encode the SMILES string\n",
        "        encoded = torch.zeros(self.max_length, self.vocab_size)\n",
        "        for i, char in enumerate(smiles[:self.max_length]):\n",
        "            encoded[i, self.char_to_idx[char]] = 1.0\n",
        "\n",
        "        return encoded.view(-1) #Flatten into 1D tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "oN5phZo8tZC1",
      "metadata": {
        "id": "oN5phZo8tZC1"
      },
      "outputs": [],
      "source": [
        "class AffineCouplingLayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        if input_dim % 2 != 0:\n",
        "            input_dim += 1\n",
        "        \n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim // 2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim // 2 * 2)\n",
        "        )\n",
        "        \n",
        "        # Initialize last layer with zeros for stable training\n",
        "        nn.init.zeros_(self.net[-1].weight)\n",
        "        nn.init.zeros_(self.net[-1].bias)\n",
        "\n",
        "    def forward(self, x, reverse=False):\n",
        "        x1, x2 = x.chunk(2, dim=1)\n",
        "        \n",
        "        # Get scaling and translation factors\n",
        "        st = self.net(x1)\n",
        "        s, t = st.chunk(2, dim=1)\n",
        "        \n",
        "        # Apply scaling with numerical stability\n",
        "        scale_factor = 0.001\n",
        "        s = torch.tanh(s) * scale_factor\n",
        "        \n",
        "        # Compute log determinant (only from the scaling part)\n",
        "        log_det = torch.sum(s, dim=1)\n",
        "        \n",
        "        if reverse:\n",
        "            # Inverse transformation\n",
        "            x2 = (x2 - t) * torch.exp(-s)\n",
        "            return torch.cat([x1, x2], dim=1), -log_det\n",
        "        else:\n",
        "            # Forward transformation\n",
        "            x2 = x2 * torch.exp(s) + t\n",
        "            return torch.cat([x1, x2], dim=1), log_det\n",
        "\n",
        "class Flow(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim + (input_dim % 2)\n",
        "        \n",
        "        # Coupling layers without batch norm\n",
        "        self.layers = nn.ModuleList([\n",
        "            AffineCouplingLayer(self.input_dim, hidden_dim)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        \n",
        "        # Layer normalization instead of batch norm\n",
        "        self.norms = nn.ModuleList([\n",
        "            nn.LayerNorm(self.input_dim)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, reverse=False):\n",
        "        # Initialize log determinant\n",
        "        log_det_total = torch.zeros(x.size(0), device=x.device)\n",
        "        \n",
        "        # Handle odd dimensions\n",
        "        if x.size(1) % 2 != 0:\n",
        "            x = F.pad(x, (0, 1), 'constant', 0)\n",
        "        \n",
        "        # Process through layers\n",
        "        if reverse:\n",
        "            for layer in reversed(self.layers):\n",
        "                x, log_det = layer(x, reverse=True)\n",
        "                log_det_total = log_det_total + log_det\n",
        "        else:\n",
        "            for layer in self.layers:\n",
        "                x, log_det = layer(x, reverse=False)\n",
        "                log_det_total = log_det_total + log_det\n",
        "        \n",
        "        return x, log_det_total\n",
        "\n",
        "    def get_latent(self, x):\n",
        "        \"\"\"Generate latent representation\"\"\"\n",
        "        z, _ = self.forward(x)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3HyjMRPVDcTs",
      "metadata": {
        "id": "3HyjMRPVDcTs"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim, latent_dim, vocab_size):\n",
        "        super(VAE, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc_mu = nn.Linear(256, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc3 = nn.Linear(latent_dim, 256)\n",
        "        self.fc4 = nn.Linear(256, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc_mu(h1), self.fc_logvar(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, self.input_dim))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, logvar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a5781a3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_vae_loss(recon_x, x, mu, logvar, dataset):\n",
        "    \"\"\"\n",
        "    Compute VAE loss with dataset-specific vocabulary size.\n",
        "    \n",
        "    Args:\n",
        "        recon_x: Reconstructed input from VAE\n",
        "        x: Original input data\n",
        "        mu: Mean from VAE encoder\n",
        "        logvar: Log variance from VAE encoder\n",
        "        dataset: Dataset object containing vocab_size and max_length\n",
        "    \"\"\"\n",
        "    batch_size = x.size(0)\n",
        "    vocab_size = dataset.vocab_size\n",
        "    seq_len = dataset.max_length\n",
        "    \n",
        "    # Reshape tensors to match dataset dimensions\n",
        "    x = x.view(batch_size, seq_len * vocab_size)\n",
        "    recon_x = recon_x.view(batch_size, seq_len * vocab_size)\n",
        "    \n",
        "    # Reconstruction loss (BCE)\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    \n",
        "    # KL divergence\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    \n",
        "    # Weight the KLD term\n",
        "    beta = 0.1  # Adjust this weight to balance reconstruction vs. KLD\n",
        "    \n",
        "    return BCE + beta * KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bb2c250f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb2c250f",
        "outputId": "14a29115-105f-4579-bbfb-d7a2758dcfe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique characters: 26\n",
            "Unique characters in dataset:\n",
            "['#', '(', ')', '-', '1', '2', '3', '4', '5', '6', '=', 'B', 'C', 'F', 'H', 'N', 'O', 'S', '[', ']', 'c', 'l', 'n', 'o', 'r', 's']\n",
            "Total: 1584663, Valid: 1584663, Invalid: 0\n",
            "Total: 176074, Valid: 176074, Invalid: 0\n",
            "Training Vocabulary Size: 26\n",
            "Test Vocabulary Size: 26\n",
            "# Train SMILES after filtering: 1584663\n",
            "# Test SMILES after filtering: 176074\n",
            "Number of batches in train_loader: 198083\n",
            "Number of batches in test_loader: 22010\n"
          ]
        }
      ],
      "source": [
        "# Load SMILES strings\n",
        "with open('dataset/train.txt', 'r') as f:\n",
        "    smiles_train = [line.strip() for line in f][1:]\n",
        "\n",
        "with open('dataset/test.txt', 'r') as f:\n",
        "    smiles_test = [line.strip() for line in f]\n",
        "\n",
        "# Apply cleaning to your SMILES\n",
        "smiles_train = [clean_smiles(smiles) for smiles in smiles_train]\n",
        "smiles_test = [clean_smiles(smiles) for smiles in smiles_test]\n",
        "smiles_train = process_smiles(smiles_train)\n",
        "smiles_test = process_smiles(smiles_test)\n",
        "smiles_train = smiles_train[:10000]\n",
        "smiles_test = smiles_test[:10000]\n",
        "\n",
        "smiles_train = load_smiles_from_csv('dataset/train.txt', split_type='train')\n",
        "smiles_test = load_smiles_from_csv('dataset/test.txt', split_type='test')  # if test rows are in same file\n",
        "\n",
        "# print(f\"Raw SMILES loaded: train={len(smiles_train)}, test={len(smiles_test)}\") # output for testing purposes\n",
        "all_smiles = smiles_train + smiles_test\n",
        "unique_chars = extract_unique_chars(all_smiles)\n",
        "\n",
        "print(f\"Total unique characters: {len(unique_chars)}\")\n",
        "print(\"Unique characters in dataset:\")\n",
        "print(unique_chars)\n",
        "\n",
        "# Use extracted unique characters to rebuild vocabulary\n",
        "VALID_CHARS = unique_chars\n",
        "char_to_idx = {c: i for i, c in enumerate(VALID_CHARS)}\n",
        "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = SMILESDataset(smiles_train, max_length=150, char_to_idx=char_to_idx)\n",
        "test_dataset = SMILESDataset(smiles_test, max_length=150, char_to_idx=char_to_idx)\n",
        "print(\"Training Vocabulary Size:\", train_dataset.vocab_size)\n",
        "print(\"Test Vocabulary Size:\", test_dataset.vocab_size) # Should be the same\n",
        "\n",
        "\n",
        "print(f\"# Train SMILES after filtering: {len(train_dataset)}\")\n",
        "print(f\"# Test SMILES after filtering: {len(test_dataset)}\")\n",
        "# train_dataset = SMILESDataset(smiles_train)\n",
        "# test_dataset = SMILESDataset(smiles_test, char_to_idx=train_dataset.char_to_idx)  # Share vocabulary\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)  # No need to shuffle test data\n",
        "\n",
        "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Number of batches in test_loader: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a8590f4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8590f4b",
        "outputId": "94bb0e95-a6c9-4808-ce3c-b270c9bb30e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "\n",
            "Sample SMILES visualizations:\n",
            "\n",
            "Sample 1\n",
            "Original : CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\n",
            "Decoded  : CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1################################################################################################################\n",
            "Shape    : torch.Size([3900])\n",
            "\n",
            "Sample 2\n",
            "Original : CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1\n",
            "Decoded  : CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1##################################################################################################################\n",
            "Shape    : torch.Size([3900])\n",
            "\n",
            "Sample 3\n",
            "Original : Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO\n",
            "Decoded  : Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO###################################################################################################################\n",
            "Shape    : torch.Size([3900])\n"
          ]
        }
      ],
      "source": [
        "# Check a batch of data\n",
        "for i, data in enumerate(train_loader):\n",
        "    if i == 0:  # Just visualize the first batch\n",
        "        print(data)\n",
        "        break\n",
        "\n",
        "# Visualize 3 samples\n",
        "print(\"\\nSample SMILES visualizations:\")\n",
        "for i in range(3):\n",
        "    encoded = train_dataset[i]\n",
        "    original = train_dataset.smiles_list[i]\n",
        "    decoded = decode_smiles(encoded, train_dataset.idx_to_char)\n",
        "\n",
        "    print(f\"\\nSample {i+1}\")\n",
        "    print(f\"Original : {original}\")\n",
        "    print(f\"Decoded  : {decoded}\")\n",
        "    print(f\"Shape    : {encoded.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "706c7ef0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Vocab size: 26\n",
            "max_length: 150\n",
            "Input dim: 3900\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import torch\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Instantiate the VAE model\n",
        "input_dim = train_dataset.vocab_size * train_dataset.max_length  # Flatten the input (max_length x vocab_size)\n",
        "latent_dim = 128\n",
        "\n",
        "vocab_size = train_dataset.vocab_size\n",
        "max_length = train_dataset.max_length\n",
        "\n",
        "print(\"Vocab size:\", train_dataset.vocab_size)\n",
        "print(\"max_length:\", train_dataset.max_length)\n",
        "print(\"Input dim:\", input_dim)\n",
        "\n",
        "flow = Flow(input_dim = input_dim, hidden_dim=256, num_layers=4).to(device)\n",
        "vae = VAE(input_dim, latent_dim, len(idx_to_char)).to(device)\n",
        "\n",
        "# Optimizer\n",
        "# Separate optimizers for Flow and VAE\n",
        "flow_optimizer = torch.optim.Adam(flow.parameters(), lr=0.0001)\n",
        "vae_optimizer = torch.optim.Adam(vae.parameters(), lr=0.0001)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 100\n",
        "early_stop_patience = 5\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "min_delta = 0.001\n",
        "\n",
        "# Lists to track losses\n",
        "flow_losses = []\n",
        "vae_losses = []\n",
        "total_losses = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "da8d0204",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, num_flow_layers):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Initialize FLOW for creating latent representation\n",
        "        self.flow = Flow(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            num_layers=num_flow_layers\n",
        "        )\n",
        "        \n",
        "        # Initialize VAE to work with FLOW's output\n",
        "        self.vae = VAE(\n",
        "            input_dim=input_dim,  # Flow preserves dimensionality\n",
        "            latent_dim=latent_dim,\n",
        "            vocab_size=vocab_size\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First pass through FLOW to get latent representation\n",
        "        z_flow, ldj = self.flow(x)\n",
        "        \n",
        "        # Use FLOW's output as input to VAE\n",
        "        recon_x, mu, logvar = self.vae(z_flow)\n",
        "        \n",
        "        return recon_x, mu, logvar, ldj, z_flow\n",
        "\n",
        "def train_step(model, data, flow_optimizer, vae_optimizer, device):\n",
        "    \"\"\"Separated training step for FLOW and VAE\"\"\"\n",
        "    data = data.to(device)\n",
        "    \n",
        "    # 1. Train FLOW\n",
        "    flow_optimizer.zero_grad()\n",
        "    z_flow, ldj = model.flow(data)\n",
        "    flow_loss = -ldj.mean()  # Maximize log-likelihood\n",
        "    flow_loss.backward()\n",
        "    flow_optimizer.step()\n",
        "    \n",
        "    # 2. Train VAE using FLOW's output (detached)\n",
        "    vae_optimizer.zero_grad()\n",
        "    with torch.no_grad():\n",
        "        z_flow, _ = model.flow(data)  # Get fresh flow output\n",
        "    recon_batch, mu, logvar = model.vae(z_flow.detach())\n",
        "    vae_loss = compute_vae_loss(recon_batch, data, mu, logvar, train_dataset)\n",
        "    vae_loss.backward()\n",
        "    vae_optimizer.step()\n",
        "    \n",
        "    return flow_loss.item(), vae_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3cf1fadf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch [100/198083] | Flow Loss: -7.6661 | VAE Loss: 7872.0625\n",
            "Batch [200/198083] | Flow Loss: -7.7870 | VAE Loss: 1328.9656\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[14], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m epoch_vae_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m---> 18\u001b[0m     flow_loss, vae_loss \u001b[38;5;241m=\u001b[39m train_step(\n\u001b[0;32m     19\u001b[0m         model, data, flow_optimizer, vae_optimizer, device\n\u001b[0;32m     20\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     epoch_flow_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m flow_loss\n\u001b[0;32m     23\u001b[0m     epoch_vae_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m vae_loss\n",
            "Cell \u001b[1;32mIn[13], line 42\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data, flow_optimizer, vae_optimizer, device)\u001b[0m\n\u001b[0;32m     40\u001b[0m vae_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 42\u001b[0m     z_flow, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mflow(data)  \u001b[38;5;66;03m# Get fresh flow output\u001b[39;00m\n\u001b[0;32m     43\u001b[0m recon_batch, mu, logvar \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mvae(z_flow\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m     44\u001b[0m vae_loss \u001b[38;5;241m=\u001b[39m compute_vae_loss(recon_batch, data, mu, logvar, train_dataset)\n",
            "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[7], line 74\u001b[0m, in \u001b[0;36mFlow.forward\u001b[1;34m(self, x, reverse)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 74\u001b[0m         x, log_det \u001b[38;5;241m=\u001b[39m layer(x, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     75\u001b[0m         log_det_total \u001b[38;5;241m=\u001b[39m log_det_total \u001b[38;5;241m+\u001b[39m log_det\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, log_det_total\n",
            "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[7], line 31\u001b[0m, in \u001b[0;36mAffineCouplingLayer.forward\u001b[1;34m(self, x, reverse)\u001b[0m\n\u001b[0;32m     28\u001b[0m s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(s) \u001b[38;5;241m*\u001b[39m scale_factor\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Compute log determinant (only from the scaling part)\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m log_det \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(s, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reverse:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Inverse transformation\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m (x2 \u001b[38;5;241m-\u001b[39m t) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39ms)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "model = CombinedModel(\n",
        "    input_dim=input_dim,\n",
        "    hidden_dim=256,\n",
        "    latent_dim=latent_dim,\n",
        "    num_flow_layers=4\n",
        ").to(device)\n",
        "\n",
        "flow_optimizer = optim.Adam(model.flow.parameters(), lr=0.0001)\n",
        "vae_optimizer = optim.Adam(model.vae.parameters(), lr=0.0001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_flow_loss = 0\n",
        "    epoch_vae_loss = 0\n",
        "    \n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        flow_loss, vae_loss = train_step(\n",
        "            model, data, flow_optimizer, vae_optimizer, device\n",
        "        )\n",
        "        \n",
        "        epoch_flow_loss += flow_loss\n",
        "        epoch_vae_loss += vae_loss\n",
        "        \n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f'Batch [{batch_idx + 1}/{len(train_loader)}] | '\n",
        "                  f'Flow Loss: {flow_loss:.4f} | '\n",
        "                  f'VAE Loss: {vae_loss:.4f}')\n",
        "\n",
        "    # Generate molecules using the trained models\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(1, latent_dim).to(device)\n",
        "        z_flow, _ = model.flow(z)\n",
        "        generated = model.vae.decode(z_flow)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MenC6MTLaiIg",
      "metadata": {
        "id": "MenC6MTLaiIg"
      },
      "source": [
        "Flow add, it created a significant drop in loss but then negative loss and break model. Possibly try to make the model stop before that happens of adjust the parameters with flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc567905",
      "metadata": {
        "id": "bc567905"
      },
      "outputs": [],
      "source": [
        "# Generate a new molecule from VAE by sampling from the latent space\n",
        "generated_smiles = generate_smiles(vae, latent_dim, train_dataset.idx_to_char, max_length, vocab_size)  # pass idx_to_char\n",
        "\n",
        "print(f\"Generated SMILES: {generated_smiles}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h-nqTr8BddZi",
      "metadata": {
        "id": "h-nqTr8BddZi"
      },
      "source": [
        "Thoughts:\n",
        "\n",
        "Potetnial invalidity due to:\n",
        "Insufficient training\n",
        "More data needed\n",
        "Expansion of latent space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gtDExC7pI0tw",
      "metadata": {
        "id": "gtDExC7pI0tw"
      },
      "source": [
        "Problems recorded:\n",
        "\n",
        "Enountered a problem where the model is taking a terabyte of data at once and breaking.\n",
        "  For now adjusted the number of strings in the dataset\n",
        "  Learned that the model is not properly breaking up the strings and just taking them whole.\n",
        "\n",
        "Encountered trouble with model only printing carbon and negative learning value\n",
        "  Learned that vocab was not correctly understood by the model\n",
        "  Adjusted how the data was recorded and one-hot encoding.\n",
        "\n",
        "VAE model original version had problems in learning and structure may be off.\n",
        "  To keep it simple for now we used a simple designed VAE version but taken from GPT as a template.\n",
        "\n",
        "Problem with FLOW use and negative Loss\n",
        "  Jacobian is improperly recorded and used. Need to rework Flow Model\n",
        "  Look into Kosaraju GLOW model as a proper reference"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
