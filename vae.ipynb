{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e53c5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moses\n",
    "import matplotlib as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d9d22e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>SPLIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1Oc2ccc(Cl)cc2N(CC(O)CO)C1=O</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SMILES  SPLIT\n",
       "0  CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1  train\n",
       "1    CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1  train\n",
       "2     Cc1c(Cl)cccc1Nc1ncccc1C(=O)OCC(O)CO  train\n",
       "3        Cn1cnc2c1c(=O)n(CC(O)CO)c(=O)n2C  train\n",
       "4          CC1Oc2ccc(Cl)cc2N(CC(O)CO)C1=O  train"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"dataset/train.txt\", sep=',')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e64afbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALID_CHARS = list(\"@=#$()%1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ[]\\\\+-/.:\")\n",
    "# char_to_idx = {c: i for i, c in enumerate(VALID_CHARS)}\n",
    "# idx_to_char = {i: c for c, i in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "062ff3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for SMILES strings\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles_list, max_length=150, char_to_idx=None):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.max_length = max_length\n",
    "\n",
    "        if char_to_idx is None:\n",
    "            raise ValueError(\"Please provide a fixed character-to-index mapping\")\n",
    "            # self.char_to_idx, self.idx_to_char = build_vocabulary(smiles_list)\n",
    "        else:\n",
    "            self.char_to_idx = char_to_idx\n",
    "            self.idx_to_char = {v: k for k, v in char_to_idx.items()}\n",
    "\n",
    "        self.vocab_size = len(self.char_to_idx)\n",
    "\n",
    "        original_count = len(smiles_list)\n",
    "        filtered = []\n",
    "        invalid_count = 0\n",
    "\n",
    "        for s in smiles_list:\n",
    "            s = s.strip()\n",
    "            if all(c in self.char_to_idx for c in s):\n",
    "                filtered.append(s)\n",
    "            else:\n",
    "                invalid_count += 1\n",
    "        print(f\"Total: {original_count}, Valid: {len(filtered)}, Invalid: {invalid_count}\")\n",
    "        self.smiles_list = filtered\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.smiles_list[idx]\n",
    "        # One-hot encode the SMILES string\n",
    "        encoded = torch.zeros(self.max_length, self.vocab_size)\n",
    "        for i, char in enumerate(smiles[:self.max_length]):\n",
    "            encoded[i, self.char_to_idx[char]] = 1.0\n",
    "\n",
    "        # # Pad with zeros\n",
    "        # if len(smiles) < self.max_length:\n",
    "        #     encoded[len(smiles):, :] = 0.0\n",
    "\n",
    "        return encoded.view(-1) #Flatten into 1D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63e2abef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)  # Increased input layer size\n",
    "        self.fc2 = nn.Linear(1024, 512)  # Added an extra hidden layer\n",
    "        self.fc3 = nn.Linear(512, 256)  # Added another extra hidden layer for more complexity\n",
    "        self.fc21 = nn.Linear(256, latent_dim)  # Mean of latent distribution\n",
    "        self.fc22 = nn.Linear(256, latent_dim)  # Log variance of latent distribution\n",
    "\n",
    "        # Decoder\n",
    "        self.fc4 = nn.Linear(latent_dim, 256)  # Mirroring Encoder structure\n",
    "        self.fc5 = nn.Linear(256, 512) # Mirroring Encoder structure\n",
    "        self.fc6 = nn.Linear(512, 1024) # Mirroring Encoder structure\n",
    "        self.fc7 = nn.Linear(1024, input_dim)  # Output layer\n",
    "\n",
    "    # Note for later, changed the architecture to add dropout\n",
    "    def encode(self, x):\n",
    "        h1 = self.dropout(F.relu(self.fc1(x)))\n",
    "        h2 = self.dropout(F.relu(self.fc2(h1)))\n",
    "        h3 = self.dropout(F.relu(self.fc3(h2)))\n",
    "        return self.fc21(h3), self.fc22(h3)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h4 = self.dropout(F.relu(self.fc4(z)))\n",
    "        h5 = self.dropout(F.relu(self.fc5(h4)))\n",
    "        h6 = self.dropout(F.relu(self.fc6(h5)))\n",
    "        return torch.sigmoid(self.fc7(h6))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, self.input_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feacf2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar, beta=0.01):\n",
    "    BCE = F.binary_cross_entropy_with_logits(recon_x, x.view(-1, recon_x.size(1)), reduction='mean')\n",
    "    # mean seemed to do better\n",
    "    KL = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KL\n",
    "\n",
    "    #return BCE + beta * KL\n",
    "# add KL annealing factor to hlelp in slowing learning and avoid KL divergence dominating loss early?\n",
    "# or binary cross entropy with logits to handle the loss\n",
    "# binary_cross_entropy vs BCE with logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c227beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_smiles_from_csv(path, split_type='train'):\n",
    "    smiles = []\n",
    "    with open(path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            if row['SPLIT'].strip().lower() == split_type:\n",
    "                smiles.append(row['SMILES'].strip())\n",
    "    return smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bd0c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_chars(smiles_list):\n",
    "    unique_chars = set()\n",
    "    for smiles in smiles_list:\n",
    "        unique_chars.update(smiles.strip())\n",
    "    return sorted(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "973932b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_smiles(smiles):\n",
    "    # Remove unwanted metadata like \",train\" or \",SPLIT\"\n",
    "    return smiles.split(',')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a34a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_smiles(one_hot_tensor, idx_to_char):\n",
    "    smiles = ''\n",
    "    one_hot_tensor = one_hot_tensor.view(-1, len(idx_to_char))  # unflatten\n",
    "    for row in one_hot_tensor:\n",
    "        idx = row.argmax().item()\n",
    "        smiles += idx_to_char[idx]\n",
    "    return smiles.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique characters: 30\n",
      "Unique characters in dataset:\n",
      "['#', '(', ')', '-', '1', '2', '3', '4', '5', '6', '=', 'B', 'C', 'E', 'F', 'H', 'I', 'L', 'M', 'N', 'O', 'S', '[', ']', 'c', 'l', 'n', 'o', 'r', 's']\n",
      "Total: 1584664, Valid: 1584664, Invalid: 0\n",
      "Total: 176075, Valid: 176075, Invalid: 0\n",
      "Training Vocabulary Size: 30\n",
      "Test Vocabulary Size: 30\n",
      "# Train SMILES after filtering: 1584664\n",
      "# Test SMILES after filtering: 176075\n",
      "Number of batches in train_loader: 198083\n",
      "Number of batches in test_loader: 22010\n"
     ]
    }
   ],
   "source": [
    "# normalize the data?\n",
    "\n",
    "# Load SMILES strings\n",
    "with open('dataset/train.txt', 'r') as f:\n",
    "    smiles_train = [line.strip() for line in f]\n",
    "\n",
    "with open('dataset/test.txt', 'r') as f:\n",
    "    smiles_test = [line.strip() for line in f]\n",
    "\n",
    "# Apply cleaning to your SMILES\n",
    "smiles_train = [clean_smiles(smiles) for smiles in smiles_train]\n",
    "smiles_test = [clean_smiles(smiles) for smiles in smiles_test]\n",
    "\n",
    "\n",
    "# smiles_train = load_smiles_from_csv('dataset/train.txt', split_type='train')\n",
    "# smiles_test = load_smiles_from_csv('dataset/test.txt', split_type='test')  # if test rows are in same file\n",
    "\n",
    "# print(f\"Raw SMILES loaded: train={len(smiles_train)}, test={len(smiles_test)}\")\n",
    "all_smiles = smiles_train + smiles_test\n",
    "unique_chars = extract_unique_chars(all_smiles)\n",
    "\n",
    "print(f\"Total unique characters: {len(unique_chars)}\")\n",
    "print(\"Unique characters in dataset:\")\n",
    "print(unique_chars)\n",
    "\n",
    "# Use extracted unique characters to rebuild vocabulary\n",
    "VALID_CHARS = unique_chars\n",
    "char_to_idx = {c: i for i, c in enumerate(VALID_CHARS)}\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SMILESDataset(smiles_train, max_length=50, char_to_idx=char_to_idx)\n",
    "test_dataset = SMILESDataset(smiles_test, max_length=50, char_to_idx=char_to_idx)\n",
    "print(\"Training Vocabulary Size:\", train_dataset.vocab_size)\n",
    "print(\"Test Vocabulary Size:\", test_dataset.vocab_size) # Should be the same\n",
    "\n",
    "\n",
    "print(f\"# Train SMILES after filtering: {len(train_dataset)}\")\n",
    "print(f\"# Test SMILES after filtering: {len(test_dataset)}\")\n",
    "# train_dataset = SMILESDataset(smiles_train)\n",
    "# test_dataset = SMILESDataset(smiles_test, char_to_idx=train_dataset.char_to_idx)  # Share vocabulary\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)  # No need to shuffle test data\n",
    "\n",
    "print(f\"Number of batches in train_loader: {len(train_loader)}\")\n",
    "print(f\"Number of batches in test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8590f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Check a batch of data\n",
    "for i, data in enumerate(train_loader):\n",
    "    if i == 0:  # Just visualize the first batch\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db7c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Save vocab to JSON\n",
    "# vocab_path = 'char_vocab.json'\n",
    "# with open(vocab_path, 'w') as f:\n",
    "#     json.dump({\n",
    "#         'char_to_idx': char_to_idx,\n",
    "#         'idx_to_char': idx_to_char\n",
    "#     }, f)\n",
    "\n",
    "# print(f\"Vocabulary saved to {vocab_path}\")\n",
    "\n",
    "# call with code below\n",
    "\n",
    "# with open('char_vocab.json', 'r') as f:\n",
    "#     vocab = json.load(f)\n",
    "#     char_to_idx = vocab['char_to_idx']\n",
    "#     idx_to_char = {int(k): v for k, v in vocab['idx_to_char'].items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "238e32e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample SMILES visualizations:\n",
      "\n",
      "Sample 1\n",
      "Original : SMILES\n",
      "Decoded  : SMILES############################################\n",
      "Shape    : torch.Size([1500])\n",
      "\n",
      "Sample 2\n",
      "Original : CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1\n",
      "Decoded  : CCCS(=O)c1ccc2[nH]c(=NC(=O)OC)[nH]c2c1############\n",
      "Shape    : torch.Size([1500])\n",
      "\n",
      "Sample 3\n",
      "Original : CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1\n",
      "Decoded  : CC(C)(C)C(=O)C(Oc1ccc(Cl)cc1)n1ccnc1##############\n",
      "Shape    : torch.Size([1500])\n"
     ]
    }
   ],
   "source": [
    "# Visualize 3 samples\n",
    "print(\"\\nSample SMILES visualizations:\")\n",
    "for i in range(3):\n",
    "    encoded = train_dataset[i]\n",
    "    original = train_dataset.smiles_list[i]\n",
    "    decoded = decode_smiles(encoded, train_dataset.idx_to_char)\n",
    "\n",
    "    print(f\"\\nSample {i+1}\")\n",
    "    print(f\"Original : {original}\")\n",
    "    print(f\"Decoded  : {decoded}\")\n",
    "    print(f\"Shape    : {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ba139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30\n",
      "max_length: 50\n",
      "Input dim: 1500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Flatten the input here before passing to the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, input_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 32\u001b[0m recon_batch, mu, logvar \u001b[38;5;241m=\u001b[39m vae(data)\n\u001b[0;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m vae_loss(recon_batch, data, mu, logvar)\n\u001b[0;32m     34\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[44], line 41\u001b[0m, in \u001b[0;36mVAE.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 41\u001b[0m     mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dim))\n\u001b[0;32m     42\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreparameterize(mu, logvar)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(z), mu, logvar\n",
      "Cell \u001b[1;32mIn[44], line 23\u001b[0m, in \u001b[0;36mVAE.encode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 23\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)))\n\u001b[0;32m     24\u001b[0m     h2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(h1)))\n\u001b[0;32m     25\u001b[0m     h3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(h2)))\n",
      "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\valde\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the VAE model\n",
    "input_dim = train_dataset.vocab_size * train_dataset.max_length  # Flatten the input (max_length x vocab_size)\n",
    "latent_dim = 128\n",
    "\n",
    "vocab_size = train_dataset.vocab_size\n",
    "max_length = train_dataset.max_length\n",
    "\n",
    "print(\"Vocab size:\", train_dataset.vocab_size)\n",
    "print(\"max_length:\", train_dataset.max_length)\n",
    "print(\"Input dim:\", input_dim)\n",
    "\n",
    "vae = VAE(input_dim, latent_dim)\n",
    "vae.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-5)\n",
    "\n",
    "# # Learning rate scheduler\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Training and Evaluation loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    vae.train()  # Set model to training mode\n",
    "    train_loss = 0\n",
    "    for data in train_loader:  # Iterate over training data\n",
    "        optimizer.zero_grad()\n",
    "        # Flatten the input here before passing to the model\n",
    "        data = data.view(-1, input_dim).to(device)\n",
    "        recon_batch, mu, logvar = vae(data)\n",
    "        #print(f\"Reconstructed output: {recon_batch[:5]}\") # testing\n",
    "        #break\n",
    "        loss = vae_loss(recon_batch, data, mu, logvar)\n",
    "        #print(f\"batch loss: {loss.item()}\") # for testing\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss/len(train_loader)}')\n",
    "\n",
    "    # Evaluation on test set\n",
    "    vae.eval()  # Set model to evaluation mode\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  # No need to calculate gradients during evaluation\n",
    "        for data in test_loader:  # Iterate over test data\n",
    "            # Flatten the input here as well\n",
    "            data = data.view(-1, input_dim).to(device)\n",
    "            recon_batch, mu, logvar = vae(data)\n",
    "            loss = vae_loss(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Test Loss: {test_loss/len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd695f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new molecule from VAE by sampling from the latent space\n",
    "def generate_smiles(model, latent_dim=64, idx_to_char=None, temperature=1.0):\n",
    "    z = torch.randn(1, latent_dim).to(model.fc1.weight.device)  # Ensure z is on the same device as the model\n",
    "    with torch.no_grad():\n",
    "        generated = model.decode(z)  # Use decode instead of decoder\n",
    "    # Add postprocessing to convert to SMILES\n",
    "    # generated_tokens_indices = torch.argmax(generated, dim=-1).cpu().numpy().flatten()\n",
    "    probs = F.softmax(generated / temperature, dim=-1)\n",
    "\n",
    "    # Sample the next character from the probability distribution\n",
    "    generated_tokens_indices = torch.multinomial(probs, 1).cpu().numpy().flatten()\n",
    "    \n",
    "    # Print generated tokens and indices for debugging\n",
    "    print(\"Generated tokens indices:\", generated_tokens_indices)\n",
    "    print(\"Generated tokens:\", [idx_to_char.get(i, \"<UNK>\") for i in generated_tokens_indices])\n",
    "    \n",
    "    # Iterate through indices to build the SMILES string\n",
    "    generated_smiles = \"\".join([idx_to_char.get(i, \"\") for i in generated_tokens_indices])\n",
    "\n",
    "    return generated_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc567905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tokens indices: [2329]\n",
      "Generated tokens: ['<UNK>']\n",
      "Generated SMILES: \n"
     ]
    }
   ],
   "source": [
    "# Generate a new molecule from VAE by sampling from the latent space\n",
    "generated_smiles = generate_smiles(vae, latent_dim, train_dataset.idx_to_char)  # pass idx_to_char\n",
    "\n",
    "print(f\"Generated SMILES: {generated_smiles}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
